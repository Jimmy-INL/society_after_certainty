{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization is the name of the game. When you think about it, what are we ultimately trying to do in model? Reduce the cost function (other names include error, objective, fitness, or utility function). We're interesting in optimizing the parameters that will transform our input to yield our target output. \n",
    "\n",
    "Optimization is large topic which shows up in a variety of contexts within machine learning, control theory, information theory, and computer science at large. At the heart of optimization is a beautiful garden of algorithms. Or perhaps it's more like a book of choreographies, indicating the steps to performed in various action sequences. Choosing an optimization strategy may be inspird by literature you read, by precedent on your team or in your community, of by from your own imagination. I find it useful to immerse yourself periodically in algorithms to remind yourself of the kind of moves that are out there, and then try them out on the \"dance floor\" (i.e. in your projects or at work). \n",
    "\n",
    "There are many forms of optimization, but here I'll focus on stocashtic optimization, as it umbrellas both stochastic gradients descent as well as the family of swarm algorithms which have become one of my true passions. Life includes random variables, and stochastic optimization understands this - folding in random numbers and random objective functions into its algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxima and Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to visualize the landscape of possible parameters for our objective function, we may observe extrema - maxima and minima (peaks and valleys). I went to high school in North Texas, so can attest to the fact that not all landscapes have readily observable extrmea. But you could imagine that while I stare out at the \"flat\" grasslands of the central plains, an ant has a markedly different estimation of what is high ground and low ground. \n",
    "\n",
    "Whether we're striding as an ant or a person, our goal in optimization is to arrive at global maxima for the function. Remember, we're looking for the absolute best paramters we can find, and don't want to get stuck on any local hilltops, or local fjords. As the nun once (could have) sung in the Sound of Music, \"climb every mountain, ford every stream, follow every rainbow, till you find the optimal paramters that mimize your cost function!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy involves a host of tools for making sure don't get stuck in local extrema on our way to global extrema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somtimes our objective function is a convex function, and therefore if there is a local minima (the \"if\" is a noteworthy caveat) then it is guarenteed to be the global minima. This comes directly from the definition of a convex function, which states that \"the line segment between any two points on the graph of [a convex] function lies above or on the graph\". A common convex function we see in the wild is least squares, including its quadratic extension in the optimization of generalized linear models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent (and hill climbing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random variable is the random point selected to optimize the step function.\n",
    "\n",
    "It's worth mentioning that sometimes you are seeking a maxima, in which case you'd want to move uphill instead of down. For more informatio on such ascents, you can check out hill climbing methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic approximation (SA)\n",
    "\n",
    "This approach tries to find extram by observing noisy data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this algorithm is interesting, because it essentially calculates extrema under certain subsets of the underlying assumptions of the model's parameters, \"extracting at random some instances of the uncertainty, and then finding the optimal solution of a problem where only the constraints associated to the extracted uncertainty instances are considered.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Nicky Case reminds us, it can be useful to \"embrace chaos\" when optimizing our models. We know there is noise in our data, so it would be dubious to presume our model is going to get the entire story right the first time out the gate. Why not allow for that noise to exist somehow in our model? That is stochastic programming's JAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulated annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximates the global optimum, as opposed to honing in on local optima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh yeah, this is exactly like it sounds. We riff off quantum theory assumptions, and even use Shrodinger's equation to proceed towards the global maxima. A nerd's paradise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Collectives \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactive search optimization (RSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic tunneling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea of STUN is to circumvent the slow dynamics of ill-shaped energy functions that one encounters for example in spin glasses by tunneling through such barriers.\n",
    "This goal is achieved by Monte Carlo sampling of a transformed function that lacks this slow dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel tempering a.k.a. replica exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've included this optimization algorithm because of its role in Monte Carlo simulations, which I hope to write more about in the future. Like a simulated annealing that doesn't need to be restarted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle swarm optimization (PSO)\n",
    "\n",
    "PSO has a lot in common with the beutiful boids simulations Craig Reynolds made in 1986. In fact, that's where PSO came from. In each time epoch, we check in with each of the agents in the system, and update the direction of their travel either by everaging the direction of those right around them (setting the number of neighbors to include) or the global direction mean of all of the agents. That's it. We update each position and press \"play\" again in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ant coloy optimization (ACO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bee colony optimization (BCO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithms \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
