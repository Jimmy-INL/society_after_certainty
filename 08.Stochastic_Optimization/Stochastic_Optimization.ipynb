{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization is the name of the game. When you think about it, what are we ultimately trying to do in model? Reduce the cost function (other names include error, objective, fitness, or utility function). We're interesting in optimizing the parameters that will transform our input to yield our target output. \n",
    "\n",
    "Optimization is large topic which shows up in a variety of contexts within machine learning, control theory, information theory, and computer science at large. At the heart of optimization is a beautiful garden of algorithms. Or perhaps it's more like a book of choreographies, indicating the steps to performed in various action sequences. Choosing an optimization strategy may be inspird by literature you read, by precedent on your team or in your community, of by from your own imagination. I find it useful to immerse yourself periodically in algorithms to remind yourself of the kind of moves that are out there, and then try them out on the \"dance floor\" (i.e. in your projects or at work). \n",
    "\n",
    "There are many forms of optimization, but here I'll focus on stocashtic optimization, as it umbrellas both stochastic gradients descent as well as the family of swarm algorithms which have become one of my true passions. Life includes random variables, and stochastic optimization understands this - folding in random numbers and random objective functions into its algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxima and Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to visualize the landscape of possible parameters for our objective function, we may observe extrema - maxima and minima (peaks and valleys). I went to high school in North Texas, so can attest to the fact that not all landscapes have readily observable extrmea. But you could imagine that while I stare out at the \"flat\" grasslands of the central plains, an ant has a markedly different estimation of what is high ground and low ground. \n",
    "\n",
    "Whether we're striding as an ant or a person, our goal in optimization is to arrive at global maxima for the function. Remember, we're looking for the absolute best paramters we can find, and don't want to get stuck on any local hilltops, or local fjords. As the nun once (could have) sung in the Sound of Music, \"climb every mountain, ford every stream, follow every rainbow, till you find the optimal paramters that mimize your cost function!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy involves a host of tools for making sure don't get stuck in local extrema on our way to global extrema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somtimes our objective function is a convex function, and therefore if there is a local minima (the \"if\" is a noteworthy caveat) then it is guarenteed to be the global minima. This comes directly from the definition of a convex function, which states that \"the line segment between any two points on the graph of [a convex] function lies above or on the graph\". A common convex function we see in the wild is least squares, including its quadratic extension in the optimization of generalized linear models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random variable is the random point selected to optimize the step function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic approximation (SA)\n",
    "\n",
    "This approach tries to find extram by observing noisy data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this algorithm is interesting, because it essentially calculates extrema under certain subsets of the underlying assumptions of the model's parameters, \"extracting at random some instances of the uncertainty, and then finding the optimal solution of a problem where only the constraints associated to the extracted uncertainty instances are considered.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulated annealing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum annealing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Collectives \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactive search optimization (RSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic tunneling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea of STUN is to circumvent the slow dynamics of ill-shaped energy functions that one encounters for example in spin glasses by tunneling through such barriers.\n",
    "This goal is achieved by Monte Carlo sampling of a transformed function that lacks this slow dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel tempering a.k.a. replica exchange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic hill climbing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle swarm optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ant coloy optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bee colony optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithms \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
